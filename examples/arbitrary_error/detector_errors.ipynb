{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import gefry2\n",
    "\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an existing problem file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./problem.pkl') as f:\n",
    "    P, obs, sigma = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning distributions\n",
    "\n",
    "First, we need to pick some probability distributions, one for each detector. These can be any of the distributions in [`scipy.stats`](http://docs.scipy.org/doc/scipy/reference/stats.html). Actually, it just has to implement the `.rvs()` method and if you need something custom I can show you what to do.\n",
    "\n",
    "**NOTE**: be careful about the spread, as there are not any checks to that count rates are positive and weird things might happen. E.g. if you picked a normal error distribution with variance of 1000 and add it to a base response of 10, you're probably going to get a lot of negative count rates and it'll get weird. \n",
    "\n",
    "**NOTE**: I'm assuming all the error distributions are independent. If you need correlated error distributions, I can implement that.\n",
    "\n",
    "As an example, I'm going to make all the detector responses add a random sample from a [triangular distribution](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.triang.html#scipy.stats.triang) and I'm going to use the same error distribution for all detectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_dists = [st.triang(1)] * len(P.detectors) # Make 15 copies of st.triang, one for each detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you must construct an object representing the distributions. These are pretty flexible and I implemented exactly what you asked (that is, just specifying a distribution for each detector) for as `background_terms.PartialRandomField`. It has a convenience method that constructs the proper object given a list of detectors and matching list of distributions. Use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "background_dist = gefry2.background_terms.PartialRandomField.from_detectors(P.detectors, error_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66666666666666663"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_dist(P.detectors[0]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to construct a problem with the detector error distributions already included (by passing the appropriate distribution object when building it), but I'm assuming you're going to be using the pre-made problem that I have already generated, which does not have distributions.\n",
    "\n",
    "I have included a convenience function that takes an old problem specification and upgrades it to the new version. The new version will have all the same parameters as the old one, but it will also upgrade the internals to the newest version and add on the distributions if you provide them. Just pass your new background term and it will replace the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_P = gefry2.Problem.upgrade_problem(P, background=background_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`new_P` is just like `P` was in terms of parameters, but the internals have been upgraded and also the error distributions tacked on. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_P.domain == P.domain ## These are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are not the same, because we added on the distributions\n",
    "new_P.detectors == P.detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But the other parameters are the same for the detectors, e.g. the location:\n",
    "all([l.loc == r.loc for l, r in zip(new_P.detectors, P.detectors)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you **cannot** resave this upgraded object to reuse. This is a fundamental limitation of Python pickles; you just need to call the upgrade every time or generate a real problem file with the background term included. E.g., this won't work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle instancemethod objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-765d2cfe3958>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'upgraded_problem.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_P\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/jmhite/.envs/source-local/lib/python2.7/copy_reg.pyc\u001b[0m in \u001b[0;36m_reduce_ex\u001b[1;34m(self, proto)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"can't pickle %s objects\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle instancemethod objects"
     ]
    }
   ],
   "source": [
    "with open('upgraded_problem.pkl', 'w') as f:\n",
    "    pickle.dump([new_P, obs, sigma], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the detector measurements\n",
    "\n",
    "Everything works like it used to, only you have a new option to control background terms in the `__call__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The methods expect to be called with a `Source` object, so I'm going to make one here that I will use as an example.\n",
    "test_src = gefry2.Source([20, 30], 1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get detector **reference** response (i.e., using the *actual* source location) without error and without background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  59.,  169.,    1.,  305.,  176.,   35.,   86.,  346.,  310.,  211.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_P(src_hyp=None, uncertain=False, background=False) # Constant (not random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get detector reference response with nominal [mean] value of background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  60.,  170.,    2.,  306.,  177.,   36.,   87.,  347.,  311.,  212.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_P(src_hyp=None, uncertain=False, background=True) # Also constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get detector response to arbitrary source, without Poisson counting errors and without background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.80000000e+02,   4.90000000e+01,   2.62100000e+03,\n",
       "         3.00000000e+00,   7.00000000e+01,   3.00000000e+00,\n",
       "         2.00000000e+00,   1.00000000e+00,   4.00000000e+00,\n",
       "         5.00000000e+00])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_P(src_hyp=test_src, uncertain=False, background=False) # Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get detector response to arbitrary source, with Poisson counting errors and without background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.97000000e+02,   4.50000000e+01,   2.61200000e+03,\n",
       "         2.00000000e+00,   7.50000000e+01,   1.00000000e+00,\n",
       "         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n",
       "         5.00000000e+00])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_P(src_hyp=test_src, uncertain=True, background=False) # This is sampled randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get detector response to arbitrary source, without Poisson counting errors and with *nominal* background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.81000000e+02,   5.00000000e+01,   2.62200000e+03,\n",
       "         4.00000000e+00,   7.10000000e+01,   4.00000000e+00,\n",
       "         3.00000000e+00,   2.00000000e+00,   5.00000000e+00,\n",
       "         6.00000000e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_P(src_hyp=test_src, uncertain=False, background=True) # Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get detector response to arbitrary source, with Poisson counting errors and with randomly sampled background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.38000000e+02,   4.40000000e+01,   2.60400000e+03,\n",
       "         1.00000000e+00,   7.30000000e+01,   4.00000000e+00,\n",
       "         4.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n",
       "         4.00000000e+00])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_P(src_hyp=test_src, uncertain=True, background=True) # Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note one combination is missing, which is \"without Poisson errors and with randomly sampled background\". I can add it if you need."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
